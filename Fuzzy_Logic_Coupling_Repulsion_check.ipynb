{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Dan Shea  \n",
    "Date: 2019.10.03\n",
    "#### Re-analyze N17, N18, and N09\n",
    "This time instead of performing $\\chi^{2}$ testing, we are only looking for cases where pairs of loci are distributed in either coupling or repulsion, with nothing in between. By definition, they will be able to reject the $H_{0}$ of a $\\chi^{2}$ test, so we forgo the test to save on computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "import os\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "import gzip\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = ['N01','N03','N04','N05','N06','N07','N08','N09','N10','N11','N12','N13','N14','N16','N17','N18','N19','N20','N21','N22',]\n",
    "filenames = ['N01_imputed_SNP_filtered_skip10000.vcf.gz','N03_imputed_SNP_filtered_skip10000.vcf.gz','N04_imputed_SNP_filtered_skip10000.vcf.gz',\n",
    "             'N05_imputed_SNP_filtered_skip10000.vcf.gz','N06_imputed_SNP_filtered_skip10000.vcf.gz','N07_imputed_SNP_filtered_skip10000.vcf.gz',\n",
    "             'N08_imputed_SNP_filtered_skip10000.vcf.gz','N09_imputed_SNP_filtered_skip10000.vcf.gz','N10_imputed_SNP_filtered_skip10000.vcf.gz',\n",
    "             'N11_imputed_SNP_filtered_skip10000.vcf.gz','N12_imputed_SNP_filtered_skip10000.vcf.gz','N13_imputed_SNP_filtered_skip10000.vcf.gz',\n",
    "             'N14_imputed_SNP_filtered_skip10000.vcf.gz','N16_imputed_SNP_filtered_skip10000.vcf.gz','N17_imputed_SNP_filtered_skip10000.vcf.gz',\n",
    "             'N18_imputed_SNP_filtered_skip10000.vcf.gz','N19_imputed_SNP_filtered_skip10000.vcf.gz','N20_imputed_SNP_filtered_skip10000.vcf.gz',\n",
    "             'N21_imputed_SNP_filtered_skip10000.vcf.gz','N22_imputed_SNP_filtered_skip10000.vcf.gz',]\n",
    "\n",
    "dfs = OrderedDict()\n",
    "for key, f in zip(samples, filenames):\n",
    "    with gzip.open(f, 'rt') as fh:\n",
    "        dfs[key] = pd.read_csv(fh, sep='\\t', header=None, comment='#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in samples:\n",
    "    dfs[key].drop(columns=[2,5,6,7,8], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in samples:\n",
    "    dfs[key].rename(columns={0: 'CHROM', 1: 'POS', 3:'REF', 4:'ALT', 9:'HITOMEBORE', 10:'FOUNDER'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in samples:\n",
    "    mapping = {k: 'RIL_{}'.format(v) for k, v in zip(dfs[key].columns[6:], range(0,len(dfs[key].columns[6:])))}\n",
    "    dfs[key].rename(columns=mapping, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_gt(x):\n",
    "    match = re.match('([01]/[01])', x)\n",
    "    if match is not None:\n",
    "        return match.group()\n",
    "    else:\n",
    "        return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in samples:\n",
    "    tmp = dfs[key].iloc[:, 4:]\n",
    "    for c in tmp.columns:\n",
    "        tmp[c] = tmp[c].apply(parse_gt)\n",
    "    dfs[key] = pd.concat([dfs[key].iloc[:, 0:4], tmp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "recoded = OrderedDict()\n",
    "for key in samples:\n",
    "    tmp_df = list()\n",
    "    for nt in dfs[key].itertuples(index=False, name=None):\n",
    "        tmp_row = list()\n",
    "        if nt[4] == '0/0' and nt[5] == '1/1':\n",
    "            for ril in nt[4:]:\n",
    "                if ril == '0/0':\n",
    "                    tmp_row.append(0)\n",
    "                elif ril == '1/1':\n",
    "                    tmp_row.append(1)\n",
    "                elif (ril == '0/1') or (ril == '1/0'):\n",
    "                    tmp_row.append(0.5)\n",
    "                else:\n",
    "                    tmp_row.append(0.5)\n",
    "        else:\n",
    "            for ril in nt[4:]:\n",
    "                if ril == '0/0':\n",
    "                    tmp_row.append(1)\n",
    "                elif ril == '1/1':\n",
    "                    tmp_row.append(0)\n",
    "                elif (ril == '0/1') or (ril == '1/0'):\n",
    "                    tmp_row.append(0.5)\n",
    "                else:\n",
    "                    tmp_row.append(0.5)\n",
    "        tmp_df.append(tmp_row)\n",
    "    recoded[key] = pd.DataFrame(tmp_df, columns=dfs[key].columns[4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dfs = OrderedDict()\n",
    "for key in samples:\n",
    "    output_dfs[key] = pd.merge(dfs[key].iloc[:,0:4], recoded[key], how='inner', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Application of Fuzzy Logic to indeterminate matching\n",
    "We want to match when the genotype at each locus is the same homozygous call (_i.e._ – $AA$ or $BB$).  \n",
    "But we also want to ignore cmparisons where one of the loci had no call (_e.g._ – $A-$) and cases where one of the loci is called to be heterozygous (_e.g._ – $AH$).  \n",
    "To accomplish this, we can vectorize the genotypes as float encodings where:\n",
    "\n",
    "| Genotype | Value |\n",
    "|----------|-------|\n",
    "| A | 0.0 |\n",
    "| H | 0.5 |\n",
    "| – | 0.5 |\n",
    "| B | 1.0 |\n",
    "\n",
    "We now have two vectors of the genotype calls of each sample at two positions $\\vec{I}$ and $\\vec{J}$.  \n",
    "To test equality you can simply ensure that given $\\vec{K}=\\vec{I}+-\\vec{J}$ the $\\sum^{n}_{i=0}\\vec{K}_{i}=0$  \n",
    "However since we wish to ignore instances where heterozygous calls or no calls occur, we instead ensure the following given $\\vec{K}=\\vec{I}+-\\vec{J}$ that $min(\\vec{K})\\neq-1.0$ and $max(\\vec{K})\\neq1.0$. As the values $-1.0$ and $1.0$ only occur in cases where $AB$ or $BA$ pairwise additions would occur in $\\vec{K}=\\vec{I}+-\\vec{J}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started processing N01\n"
     ]
    }
   ],
   "source": [
    "results_df = OrderedDict()\n",
    "for key in ['N01']:\n",
    "    results_df[key] = list()\n",
    "    print('Started processing {}'.format(key))\n",
    "    for i in range(0, output_dfs[key].shape[0]-1):\n",
    "        for j in range(i+1, output_dfs[key].shape[0]):\n",
    "            if output_dfs[key].iloc[i, 0] != output_dfs[key].iloc[j, 0]:\n",
    "                tmp_a = np.array(output_dfs[key].iloc[i, 6:])\n",
    "                tmp_b = -1 * np.array(output_dfs[key].iloc[j, 6:])\n",
    "                tmp_sum = tmp_a + tmp_b\n",
    "                tmp_min = np.min(tmp_sum)\n",
    "                tmp_max = np.max(tmp_sum)\n",
    "                flag = True\n",
    "                if (tmp_min == -1.0) or (tmp_max == 1.0):\n",
    "                    flag = False\n",
    "                \n",
    "                if flag:\n",
    "                    tmp_row = list(output_dfs[key].iloc[i, :])\n",
    "                    tmp_row.extend(list(output_dfs[key].iloc[j, :]))\n",
    "                    results_df[key].append(tmp_row)\n",
    "    results_df[key] = pd.DataFrame(results_df[key])\n",
    "    print('Finished processing {}'.format(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in candidates:\n",
    "    results_df['N01']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
