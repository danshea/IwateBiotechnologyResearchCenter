{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Dan Shea  \n",
    "Date: 2019.10.03\n",
    "#### Re-analyze N17, N18, and N09\n",
    "This time instead of performing $\\chi^{2}$ testing, we are only looking for cases where pairs of loci are distributed in either coupling or repulsion, with nothing in between. By definition, they will be able to reject the $H_{0}$ of a $\\chi^{2}$ test, so we forgo the test to save on computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "import os\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "import gzip\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = ['N01','N03','N04','N05','N06','N07','N08','N09','N10','N11','N12','N13','N14','N16','N17','N18','N19','N20','N21','N22',]\n",
    "filenames = ['N01_imputed_SNP_filtered_skip10000.vcf.gz','N03_imputed_SNP_filtered_skip10000.vcf.gz','N04_imputed_SNP_filtered_skip10000.vcf.gz',\n",
    "             'N05_imputed_SNP_filtered_skip10000.vcf.gz','N06_imputed_SNP_filtered_skip10000.vcf.gz','N07_imputed_SNP_filtered_skip10000.vcf.gz',\n",
    "             'N08_imputed_SNP_filtered_skip10000.vcf.gz','N09_imputed_SNP_filtered_skip10000.vcf.gz','N10_imputed_SNP_filtered_skip10000.vcf.gz',\n",
    "             'N11_imputed_SNP_filtered_skip10000.vcf.gz','N12_imputed_SNP_filtered_skip10000.vcf.gz','N13_imputed_SNP_filtered_skip10000.vcf.gz',\n",
    "             'N14_imputed_SNP_filtered_skip10000.vcf.gz','N16_imputed_SNP_filtered_skip10000.vcf.gz','N17_imputed_SNP_filtered_skip10000.vcf.gz',\n",
    "             'N18_imputed_SNP_filtered_skip10000.vcf.gz','N19_imputed_SNP_filtered_skip10000.vcf.gz','N20_imputed_SNP_filtered_skip10000.vcf.gz',\n",
    "             'N21_imputed_SNP_filtered_skip10000.vcf.gz','N22_imputed_SNP_filtered_skip10000.vcf.gz',]\n",
    "\n",
    "dfs = OrderedDict()\n",
    "for key, f in zip(samples, filenames):\n",
    "    with gzip.open(f, 'rt') as fh:\n",
    "        dfs[key] = pd.read_csv(fh, sep='\\t', header=None, comment='#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in samples:\n",
    "    dfs[key].drop(columns=[2,5,6,7,8], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in samples:\n",
    "    dfs[key].rename(columns={0: 'CHROM', 1: 'POS', 3:'REF', 4:'ALT', 9:'HITOMEBORE', 10:'FOUNDER'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in samples:\n",
    "    mapping = {k: 'RIL_{}'.format(v) for k, v in zip(dfs[key].columns[6:], range(0,len(dfs[key].columns[6:])))}\n",
    "    dfs[key].rename(columns=mapping, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_gt(x):\n",
    "    match = re.match('([01]/[01])', x)\n",
    "    if match is not None:\n",
    "        return match.group()\n",
    "    else:\n",
    "        return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in samples:\n",
    "    tmp = dfs[key].iloc[:, 4:]\n",
    "    for c in tmp.columns:\n",
    "        tmp[c] = tmp[c].apply(parse_gt)\n",
    "    dfs[key] = pd.concat([dfs[key].iloc[:, 0:4], tmp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "recoded = OrderedDict()\n",
    "for key in samples:\n",
    "    tmp_df = list()\n",
    "    for nt in dfs[key].itertuples(index=False, name=None):\n",
    "        tmp_row = list()\n",
    "        if nt[4] == '0/0' and nt[5] == '1/1':\n",
    "            for ril in nt[4:]:\n",
    "                if ril == '0/0':\n",
    "                    tmp_row.append('A')\n",
    "                elif ril == '1/1':\n",
    "                    tmp_row.append('B')\n",
    "                elif (ril == '0/1') or (ril == '1/0'):\n",
    "                    tmp_row.append('H')\n",
    "                else:\n",
    "                    tmp_row.append('-')\n",
    "        else:\n",
    "            for ril in nt[4:]:\n",
    "                if ril == '0/0':\n",
    "                    tmp_row.append('B')\n",
    "                elif ril == '1/1':\n",
    "                    tmp_row.append('A')\n",
    "                elif (ril == '0/1') or (ril == '1/0'):\n",
    "                    tmp_row.append('H')\n",
    "                else:\n",
    "                    tmp_row.append('-')\n",
    "        tmp_df.append(tmp_row)\n",
    "    recoded[key] = pd.DataFrame(tmp_df, columns=dfs[key].columns[4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_nohetero(r):\n",
    "    for i in r:\n",
    "        if i == 'H':\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N01 contains 43 loci with 0 heterozygous calls.\n",
      "N03 contains 1892 loci with 0 heterozygous calls.\n",
      "N04 contains 281 loci with 0 heterozygous calls.\n",
      "N05 contains 123 loci with 0 heterozygous calls.\n",
      "N06 contains 808 loci with 0 heterozygous calls.\n",
      "N07 contains 4904 loci with 0 heterozygous calls.\n",
      "N08 contains 1470 loci with 0 heterozygous calls.\n",
      "N09 contains 3 loci with 0 heterozygous calls.\n",
      "N10 contains 0 loci with 0 heterozygous calls.\n",
      "N11 contains 3333 loci with 0 heterozygous calls.\n",
      "N12 contains 1069 loci with 0 heterozygous calls.\n",
      "N13 contains 4330 loci with 0 heterozygous calls.\n",
      "N14 contains 13719 loci with 0 heterozygous calls.\n",
      "N16 contains 15692 loci with 0 heterozygous calls.\n",
      "N17 contains 205 loci with 0 heterozygous calls.\n",
      "N18 contains 0 loci with 0 heterozygous calls.\n",
      "N19 contains 17 loci with 0 heterozygous calls.\n",
      "N20 contains 6 loci with 0 heterozygous calls.\n",
      "N21 contains 0 loci with 0 heterozygous calls.\n",
      "N22 contains 0 loci with 0 heterozygous calls.\n"
     ]
    }
   ],
   "source": [
    "for key in samples:\n",
    "    print('{} contains {} loci with 0 heterozygous calls.'.format(key, sum(recoded[key].apply(is_nohetero, axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dfs = OrderedDict()\n",
    "for key in samples:\n",
    "    output_dfs[key] = pd.merge(dfs[key].iloc[:,0:4], recoded[key][recoded[key].apply(is_nohetero, axis=1)], how='inner', left_index=True, right_index=True)\n",
    "    output_dfs[key].to_csv('{}_homozygous_loci.tsv.gz'.format(key), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N03 contains purely homozygous loci on ['chr01', 'chr03', 'chr04', 'chr05', 'chr06', 'chr07', 'chr08', 'chr09', 'chr10', 'chr11', 'chr12'].\n",
      "N04 contains purely homozygous loci on ['chr04', 'chr05', 'chr08', 'chr10', 'chr12'].\n",
      "N05 contains purely homozygous loci on ['chr01', 'chr02', 'chr03', 'chr04', 'chr07', 'chr08', 'chr09', 'chr10'].\n",
      "N06 contains purely homozygous loci on ['chr01', 'chr02', 'chr03', 'chr04', 'chr06', 'chr07', 'chr08', 'chr09', 'chr11'].\n",
      "N07 contains purely homozygous loci on ['chr01', 'chr02', 'chr03', 'chr04', 'chr05', 'chr06', 'chr07', 'chr08', 'chr09', 'chr10', 'chr11', 'chr12'].\n",
      "N08 contains purely homozygous loci on ['chr01', 'chr02', 'chr03', 'chr04', 'chr05', 'chr06', 'chr07', 'chr08', 'chr09', 'chr10', 'chr11', 'chr12'].\n",
      "N11 contains purely homozygous loci on ['chr01', 'chr02', 'chr03', 'chr04', 'chr05', 'chr06', 'chr07', 'chr08', 'chr09', 'chr10', 'chr11', 'chr12'].\n",
      "N12 contains purely homozygous loci on ['chr01', 'chr02', 'chr03', 'chr04', 'chr05', 'chr06', 'chr07', 'chr08', 'chr09', 'chr10', 'chr11', 'chr12'].\n",
      "N13 contains purely homozygous loci on ['chr01', 'chr02', 'chr03', 'chr04', 'chr05', 'chr06', 'chr07', 'chr08', 'chr09', 'chr10', 'chr11', 'chr12'].\n",
      "N14 contains purely homozygous loci on ['chr01', 'chr02', 'chr03', 'chr04', 'chr05', 'chr06', 'chr07', 'chr08', 'chr09', 'chr10', 'chr11', 'chr12'].\n",
      "N16 contains purely homozygous loci on ['chr01', 'chr02', 'chr03', 'chr04', 'chr05', 'chr06', 'chr07', 'chr08', 'chr09', 'chr10', 'chr11', 'chr12'].\n",
      "N17 contains purely homozygous loci on ['chr01', 'chr02', 'chr03', 'chr04', 'chr05', 'chr06', 'chr07', 'chr08', 'chr09', 'chr10', 'chr12'].\n",
      "N19 contains purely homozygous loci on ['chr02', 'chr03'].\n"
     ]
    }
   ],
   "source": [
    "for key in samples:\n",
    "    S = sorted(set(output_dfs[key].CHROM))\n",
    "    if len(S) > 1:\n",
    "        print('{} contains purely homozygous loci on {}.'.format(key, S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started processing N03\n",
      "Finished processing N03\n",
      "Started processing N04\n",
      "Finished processing N04\n",
      "Started processing N05\n",
      "Finished processing N05\n",
      "Started processing N06\n",
      "Finished processing N06\n",
      "Started processing N07\n",
      "Finished processing N07\n",
      "Started processing N08\n",
      "Finished processing N08\n",
      "Started processing N11\n",
      "Finished processing N11\n",
      "Started processing N12\n",
      "Finished processing N12\n",
      "Started processing N13\n",
      "Finished processing N13\n",
      "Started processing N14\n",
      "Finished processing N14\n",
      "Started processing N16\n",
      "Finished processing N16\n",
      "Started processing N17\n",
      "Finished processing N17\n",
      "Started processing N19\n",
      "Finished processing N19\n"
     ]
    }
   ],
   "source": [
    "candidates = ['N03', 'N04', 'N05', 'N06', 'N07', 'N08', 'N11', 'N12', 'N13', 'N14', 'N16', 'N17', 'N19']\n",
    "results_df = OrderedDict()\n",
    "for key in candidates:\n",
    "    results_df[key] = list()\n",
    "    print('Started processing {}'.format(key))\n",
    "    for i in range(0, output_dfs[key].shape[0]-1):\n",
    "        for j in range(i+1, output_dfs[key].shape[0]):\n",
    "            if output_dfs[key].iloc[i, 0] != output_dfs[key].iloc[j, 0]:\n",
    "                tmp = list(zip(output_dfs[key].iloc[i, 6:], output_dfs[key].iloc[j, 6:]))\n",
    "                flag = True\n",
    "                for ta, tb in tmp:\n",
    "                    # If we get AB or BA move on to the next\n",
    "                    if (ta == 'A') and (tb == 'B'):\n",
    "                        flag = False\n",
    "                        break\n",
    "                    if (ta == 'B') and (tb == 'A'):\n",
    "                        flag = False\n",
    "                        break\n",
    "                if flag:\n",
    "                    tmp_row = list(output_dfs[key].iloc[i, :])\n",
    "                    tmp_row.extend(list(output_dfs[key].iloc[j, :]))\n",
    "                    results_df[key].append(tmp_row)\n",
    "    results_df[key] = pd.DataFrame(results_df[key])\n",
    "    print('Finished processing {}'.format(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in candidates:\n",
    "    results_df[key].to_csv('{}_nohetero_CouplingAnalyzer.tsv.gz'.format(key), sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
